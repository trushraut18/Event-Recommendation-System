# -*- coding: utf-8 -*-
"""code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jH48gihzWwWmjq8b7xlO3P8r7WZ5pyyv
"""

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer

!pip install nltk
import nltk

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')

import re
import string
from nltk.stem import WordNetLemmatizer
from nltk import word_tokenize
from nltk.corpus import stopwords

df = pd.read_csv('CCMLEmployeeData.csv')
events= pd.read_csv('events.csv')

df.dropna(inplace=True)

df['Name']= df['Name'].astype(str)
df['Domain']= df['Domain'].astype(str)
df['Event1']= df['Event1'].astype(str)
df['Event2']= df['Event2'].astype(str)

df["Domain"] = [x.lower().replace(' ','') for x in df["Domain"]]
df["Event1"] = [x.lower().replace(' ','') for x in df["Event1"]]
df["Event2"] = [x.lower().replace(' ','') for x in df["Event2"]]

Employee_domains = set(df["Domain"] )
Employee_domains   # length = 23

frames = [df["Event1"] , df["Event2"] ]
Types =set(pd.concat(frames))
Types #length = 13

df["Bag_of_words"] = ''
columns = ['Domain','Event1','Event2']
for index, row in df.iterrows():
    words = ''
    for col in columns:
        words += ''.join(row[col]) + ' '
    row['Bag_of_words'] = words

df["Bag_of_words"].head(5)

df = df[['Name','Bag_of_words']]
df.head(5)

stop = stopwords.words('english')
stop_words_ = set(stopwords.words('english'))
wn = WordNetLemmatizer()

def black_txt(token):
    return  token not in stop_words_ and token not in list(string.punctuation)  and len(token)>2   
  
def clean_txt(text):
  clean_text = []
  clean_text2 = []
  text = re.sub("'", "",text)
  text=re.sub("(\\d|\\W)+"," ",text) 
  text = text.replace("nbsp", "")
  clean_text = [ wn.lemmatize(word, pos="v") for word in word_tokenize(text.lower()) if black_txt(word)]
  clean_text2 = [word for word in clean_text if black_txt(word)]
  return " ".join(clean_text2)

df['Bag_of_words'] =df['Bag_of_words'].apply(clean_txt)

count = CountVectorizer()
count_matrix = count.fit_transform(df['Bag_of_words'])
cosine_sim = cosine_similarity(count_matrix, count_matrix)
print(cosine_sim)

indices = pd.Series(events['events'])
indices.head(5)

def recommend(events, cosine_sim = cosine_sim):
    recommended_event = []
    idx = indices[indices == events].index[0]
    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)
    all_recommended_people =list(score_series.iloc[0:5].index)
   
    for i in all_recommended_people:
        recommended_event.append(list(df['Name'])[i])
    
    return recommended_event

input_event = input() 
#input  -> work from home internship from learntricks edutech

recomended_people = recommend(input_event)
recomended_people

Output_dataframe = {'Event' : input_event,'Recomended_employees' :[recomended_people]}
Output_dataframe

Final_dataframe = pd.DataFrame(Output_dataframe, columns = ['Event', 'Recomended_employees'])
Final_dataframe

output = "result.xlsx" #xlsx file will take few minutes to generate
Final_dataframe.to_excel(output)
Final_dataframe